{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "200eb016-d58a-41c8-8335-3e1ca327ae05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48323858-cddc-4d8a-8262-1a5e763e8027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of left input samples: 1119\n",
      "Number of right input samples: 1119\n",
      "Number of target samples: 1120\n",
      "./output_images/output/left/image_depth_1701624237_257517568.jpg | ./output_images/depth/image_depth_1701624237_257517568.jpg\n",
      "./output_images/output/left/image_depth_1701624238_197022720.jpg | ./output_images/depth/image_depth_1701624238_197022720.jpg\n",
      "./output_images/output/left/image_depth_1701624238_857298688.jpg | ./output_images/depth/image_depth_1701624238_857298688.jpg\n",
      "./output_images/output/left/image_depth_1701624239_787462144.jpg | ./output_images/depth/image_depth_1701624239_787462144.jpg\n",
      "./output_images/output/left/image_depth_1701624240_603289856.jpg | ./output_images/depth/image_depth_1701624240_603289856.jpg\n",
      "./output_images/output/left/image_depth_1701624241_240535808.jpg | ./output_images/depth/image_depth_1701624241_240535808.jpg\n",
      "./output_images/output/left/image_depth_1701624241_954830080.jpg | ./output_images/depth/image_depth_1701624241_954830080.jpg\n",
      "./output_images/output/left/image_depth_1701624242_680630272.jpg | ./output_images/depth/image_depth_1701624242_680630272.jpg\n",
      "./output_images/output/left/image_depth_1701624243_420094464.jpg | ./output_images/depth/image_depth_1701624243_420094464.jpg\n",
      "./output_images/output/left/image_depth_1701624244_297048064.jpg | ./output_images/depth/image_depth_1701624244_297048064.jpg\n"
     ]
    }
   ],
   "source": [
    "# Prepare paths of input images and target segmentation masks\n",
    "left_input_dir = \"./output_images/output/left/\"\n",
    "right_input_dir = \"./output_images/output/right/\"\n",
    "depth_dir = \"./output_images/depth\"\n",
    "\n",
    "img_size = (320, 320)          #This is the biggest image I could get\n",
    "num_classes = 4\n",
    "batch_size = 16                # Bigger sizes sometimes couse crashes due to low memory\n",
    "lower_color_threshold = 100\n",
    "\n",
    "\n",
    "# Sorting image names in left input folder\n",
    "left_input_img_paths = sorted([\n",
    "    os.path.join(left_input_dir, fname)\n",
    "    for fname in os.listdir(left_input_dir)\n",
    "    if fname.endswith(\".jpg\")\n",
    "])\n",
    "\n",
    "# Sorting image names in left input folder\n",
    "right_input_img_paths = sorted([\n",
    "    os.path.join(right_input_dir, fname)\n",
    "    for fname in os.listdir(right_input_dir)\n",
    "    if fname.endswith(\".jpg\")\n",
    "])\n",
    "\n",
    "# Sorting image names in target folder\n",
    "target_img_paths = sorted([\n",
    "    os.path.join(depth_dir, fname)\n",
    "    for fname in os.listdir(depth_dir)\n",
    "    if fname.endswith(\".jpg\")\n",
    "])\n",
    "\n",
    "print(\"Number of left input samples:\", len(left_input_img_paths))\n",
    "print(\"Number of right input samples:\", len(right_input_img_paths))\n",
    "print(\"Number of target samples:\", len(target_img_paths))\n",
    "\n",
    "#Input and target images are now corresponding\n",
    "for input_path, target_path in zip(left_input_img_paths[:10], target_img_paths[:10]):\n",
    "    print(input_path, \"|\", target_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a1d53c-690a-4c67-af5f-631e9a2f80b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(path, size):\n",
    "    img = cv2.imread(path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, size)\n",
    "    return img\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(40, 20))\n",
    "\n",
    "index = 100\n",
    "size= (640, 360)\n",
    "\n",
    "# Assuming there are exactly three images\n",
    "axes[0].imshow(load_image(left_input_img_paths[index], size))\n",
    "axes[0].set_title(\"Left image\")\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(load_image(right_input_img_paths[index], size))\n",
    "axes[1].set_title(\"Right image\")\n",
    "axes[1].axis('off')\n",
    "\n",
    "axes[2].imshow(load_image(target_img_paths[index], size))\n",
    "axes[2].set_title(\"Depth image\")\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
